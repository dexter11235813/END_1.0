{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "model2.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StuZqZ-Xr8r6",
        "outputId": "f3f5f60d-37ee-4922-aa7a-1a5b7fd04c8d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 14 16:32:27 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P0    41W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TG71kv7sFLF"
      },
      "source": [
        "#!python -m spacy download de_core_news_sm\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eygmVxl2r5gk"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "import spacy \n",
        "import numpy as np \n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2h1ydn0r5gs"
      },
      "source": [
        "SEED = 1234\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1wk0FuYr5gt"
      },
      "source": [
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z1RqlEPr5gt"
      },
      "source": [
        "SRC = Field(tokenize = tokenize_en,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>',\n",
        "            lower=True, include_lengths=True)\n",
        "\n",
        "TRG = Field(tokenize=tokenize_de,\n",
        "            init_token='<sos>',\n",
        "            eos_token='<eos>',\n",
        "            lower=True)\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.de'), fields=(SRC, TRG))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_Kx91JUr5gu"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "SRC.build_vocab(train_data, min_freq=2)\n",
        "TRG.build_vocab(train_data, min_freq=2)\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size=BATCH_SIZE, device='cuda', sort_within_batch=True, sort_key=lambda x: len(x.src)\n",
        ")\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev4LCaVQr5gu"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        \n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_len):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        \n",
        "        #embedded = [src len, batch size, emb dim]\n",
        "                \n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.cpu())\n",
        "                \n",
        "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
        "                                 \n",
        "        #packed_outputs is a packed sequence containing all hidden states\n",
        "        #hidden is now from the final non-padded element in the batch\n",
        "            \n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
        "            \n",
        "        #outputs is now a non-packed sequence, all hidden states obtained\n",
        "        #  when the input is a pad token are all zeros\n",
        "            \n",
        "        #outputs = [src len, batch size, hid dim * num directions]\n",
        "        #hidden = [n layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
        "        #outputs are always from the last layer\n",
        "        \n",
        "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
        "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
        "        \n",
        "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
        "        #  encoder RNNs fed through a linear layer\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        \n",
        "        #outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        \n",
        "        return outputs, hidden\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
        "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
        "        \n",
        "    def forward(self, hidden, encoder_outputs, mask):\n",
        "        \n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        \n",
        "        batch_size = encoder_outputs.shape[1]\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "        \n",
        "        #repeat decoder hidden state src_len times\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "  \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #hidden = [batch size, src len, dec hid dim]\n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
        "        \n",
        "        #energy = [batch size, src len, dec hid dim]\n",
        "\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        \n",
        "        #attention = [batch size, src len]\n",
        "        \n",
        "        attention = attention.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        return F.softmax(attention, dim = 1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_dim = output_dim\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        \n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        \n",
        "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, input, hidden, encoder_outputs, mask):\n",
        "             \n",
        "        #input = [batch size]\n",
        "        #hidden = [batch size, dec hid dim]\n",
        "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
        "        #mask = [batch size, src len]\n",
        "        \n",
        "        input = input.unsqueeze(0)\n",
        "        \n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]\n",
        "        \n",
        "        a = self.attention(hidden, encoder_outputs, mask)\n",
        "                \n",
        "        #a = [batch size, src len]\n",
        "        \n",
        "        a = a.unsqueeze(1)\n",
        "        \n",
        "        #a = [batch size, 1, src len]\n",
        "        \n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        \n",
        "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
        "        \n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        \n",
        "        #weighted = [batch size, 1, enc hid dim * 2]\n",
        "        \n",
        "        weighted = weighted.permute(1, 0, 2)\n",
        "        \n",
        "        #weighted = [1, batch size, enc hid dim * 2]\n",
        "        \n",
        "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
        "        \n",
        "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
        "            \n",
        "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
        "        \n",
        "        #output = [seq len, batch size, dec hid dim * n directions]\n",
        "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
        "        \n",
        "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
        "        #output = [1, batch size, dec hid dim]\n",
        "        #hidden = [1, batch size, dec hid dim]\n",
        "        #this also means that output == hidden\n",
        "        assert (output == hidden).all()\n",
        "        \n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted = weighted.squeeze(0)\n",
        "        \n",
        "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
        "        \n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden.squeeze(0), a.squeeze(1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkYMB3ylr5gv"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def create_mask(self, src):\n",
        "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
        "        return mask\n",
        "        \n",
        "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #src_len = [batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
        "                    \n",
        "        batch_size = src.shape[1]\n",
        "        trg_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        \n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        \n",
        "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
        "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
        "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
        "                \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = trg[0,:]\n",
        "        \n",
        "        mask = self.create_mask(src)\n",
        "\n",
        "        #mask = [batch size, src len]\n",
        "                \n",
        "        for t in range(1, trg_len):\n",
        "            \n",
        "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
        "            #  and mask\n",
        "            #receive output tensor (predictions) and new hidden state\n",
        "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = trg[t] if teacher_force else top1\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTiBaUhEr5gw"
      },
      "source": [
        "device='cuda'\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 512\n",
        "DEC_HID_DIM = 512\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzMi_jwNr5gw",
        "outputId": "78834578-08d7-40c5-a85e-9c92bbd3812d"
      },
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "model.apply(init_weights)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5923, 256)\n",
              "    (rnn): GRU(256, 512, bidirectional=True)\n",
              "    (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=1536, out_features=512, bias=True)\n",
              "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
              "    )\n",
              "    (embedding): Embedding(7873, 256)\n",
              "    (rnn): GRU(1280, 512)\n",
              "    (fc_out): Linear(in_features=1792, out_features=7873, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj8GLLApr5gx"
      },
      "source": [
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src, src_len = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(src, src_len, trg)\n",
        "        \n",
        "        #trg = [trg len, batch size]\n",
        "        #output = [trg len, batch size, output dim]\n",
        "        \n",
        "        output_dim = output.shape[-1]\n",
        "        \n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "        \n",
        "        #trg = [(trg len - 1) * batch size]\n",
        "        #output = [(trg len - 1) * batch size, output dim]\n",
        "        \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src, src_len = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, src_len, trg, 0) #turn off teacher forcing\n",
        "            \n",
        "            #trg = [trg len, batch size]\n",
        "            #output = [trg len, batch size, output dim]\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            #trg = [(trg len - 1) * batch size]\n",
        "            #output = [(trg len - 1) * batch size, output dim]\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDrF4vPVtF_R"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB0bCvm5r5gy",
        "outputId": "9a811318-4a0c-4066-8f76-26d601bd106a"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        #torch.save(model.state_dict(), 'tut4-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {np.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {np.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 42s\n",
            "\tTrain Loss: 5.150 | Train PPL: 172.348\n",
            "\t Val. Loss: 4.906 |  Val. PPL: 135.068\n",
            "Epoch: 02 | Time: 0m 42s\n",
            "\tTrain Loss: 4.063 | Train PPL:  58.164\n",
            "\t Val. Loss: 4.175 |  Val. PPL:  65.065\n",
            "Epoch: 03 | Time: 0m 42s\n",
            "\tTrain Loss: 3.289 | Train PPL:  26.818\n",
            "\t Val. Loss: 3.566 |  Val. PPL:  35.386\n",
            "Epoch: 04 | Time: 0m 42s\n",
            "\tTrain Loss: 2.730 | Train PPL:  15.340\n",
            "\t Val. Loss: 3.320 |  Val. PPL:  27.654\n",
            "Epoch: 05 | Time: 0m 42s\n",
            "\tTrain Loss: 2.327 | Train PPL:  10.252\n",
            "\t Val. Loss: 3.231 |  Val. PPL:  25.295\n",
            "Epoch: 06 | Time: 0m 42s\n",
            "\tTrain Loss: 1.995 | Train PPL:   7.353\n",
            "\t Val. Loss: 3.156 |  Val. PPL:  23.466\n",
            "Epoch: 07 | Time: 0m 42s\n",
            "\tTrain Loss: 1.727 | Train PPL:   5.621\n",
            "\t Val. Loss: 3.206 |  Val. PPL:  24.681\n",
            "Epoch: 08 | Time: 0m 42s\n",
            "\tTrain Loss: 1.571 | Train PPL:   4.812\n",
            "\t Val. Loss: 3.254 |  Val. PPL:  25.905\n",
            "Epoch: 09 | Time: 0m 42s\n",
            "\tTrain Loss: 1.409 | Train PPL:   4.090\n",
            "\t Val. Loss: 3.315 |  Val. PPL:  27.533\n",
            "Epoch: 10 | Time: 0m 42s\n",
            "\tTrain Loss: 1.262 | Train PPL:   3.533\n",
            "\t Val. Loss: 3.354 |  Val. PPL:  28.629\n",
            "Epoch: 11 | Time: 0m 42s\n",
            "\tTrain Loss: 1.158 | Train PPL:   3.183\n",
            "\t Val. Loss: 3.432 |  Val. PPL:  30.947\n",
            "Epoch: 12 | Time: 0m 42s\n",
            "\tTrain Loss: 1.082 | Train PPL:   2.950\n",
            "\t Val. Loss: 3.435 |  Val. PPL:  31.039\n",
            "Epoch: 13 | Time: 0m 42s\n",
            "\tTrain Loss: 0.946 | Train PPL:   2.577\n",
            "\t Val. Loss: 3.543 |  Val. PPL:  34.559\n",
            "Epoch: 14 | Time: 0m 42s\n",
            "\tTrain Loss: 0.887 | Train PPL:   2.427\n",
            "\t Val. Loss: 3.622 |  Val. PPL:  37.404\n",
            "Epoch: 15 | Time: 0m 42s\n",
            "\tTrain Loss: 0.833 | Train PPL:   2.300\n",
            "\t Val. Loss: 3.647 |  Val. PPL:  38.364\n",
            "Epoch: 16 | Time: 0m 42s\n",
            "\tTrain Loss: 0.745 | Train PPL:   2.107\n",
            "\t Val. Loss: 3.770 |  Val. PPL:  43.394\n",
            "Epoch: 17 | Time: 0m 42s\n",
            "\tTrain Loss: 0.707 | Train PPL:   2.028\n",
            "\t Val. Loss: 3.863 |  Val. PPL:  47.612\n",
            "Epoch: 18 | Time: 0m 42s\n",
            "\tTrain Loss: 0.647 | Train PPL:   1.910\n",
            "\t Val. Loss: 3.908 |  Val. PPL:  49.821\n",
            "Epoch: 19 | Time: 0m 42s\n",
            "\tTrain Loss: 0.582 | Train PPL:   1.790\n",
            "\t Val. Loss: 3.980 |  Val. PPL:  53.502\n",
            "Epoch: 20 | Time: 0m 42s\n",
            "\tTrain Loss: 0.560 | Train PPL:   1.750\n",
            "\t Val. Loss: 4.046 |  Val. PPL:  57.188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDfP5io2zlQv"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\r\n",
        "\r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('de')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "        \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "    \r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "    src_len = torch.LongTensor([len(src_indexes)]).to(device)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        encoder_outputs, hidden = model.encoder(src_tensor, src_len)\r\n",
        "\r\n",
        "    mask = model.create_mask(src_tensor)\r\n",
        "        \r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    attentions = torch.zeros(max_len, 1, len(src_indexes)).to(device)\r\n",
        "    \r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\r\n",
        "                \r\n",
        "        with torch.no_grad():\r\n",
        "            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs, mask)\r\n",
        "\r\n",
        "        attentions[i] = attention\r\n",
        "            \r\n",
        "        pred_token = output.argmax(1).item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak2EDnSer5gy"
      },
      "source": [
        "def display_attention(sentence, translation, attention):\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize=(10,10))\r\n",
        "    ax = fig.add_subplot(111)\r\n",
        "    \r\n",
        "    attention = attention.squeeze(1).cpu().detach().numpy()\r\n",
        "    \r\n",
        "    cax = ax.matshow(attention, cmap='bone')\r\n",
        "   \r\n",
        "    ax.tick_params(labelsize=15)\r\n",
        "    ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
        "                       rotation=45)\r\n",
        "    ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()\r\n",
        "    plt.close()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTeZJkLZzjb9",
        "outputId": "e0b7292b-fc28-4a7d-c8d7-74c4eea8a4cd"
      },
      "source": [
        "example_idx = 12\r\n",
        "\r\n",
        "src = vars(valid_data.examples[example_idx])['src']\r\n",
        "trg = vars(valid_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['three', 'young', 'children', 'stand', 'around', 'a', 'blue', 'and', 'white', 'barrel', '.']\n",
            "trg = ['drei', 'kleine', 'kinder', 'stehen', 'um', 'ein', 'blau', '-', 'weißes', 'fass', 'herum', '.']\n",
            "predicted trg = ['drei', 'kleine', 'kinder', 'stehen', 'um', 'eine', 'blau', 'und', 'weißen', '<unk>', '.', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "-waxVqKDzppz",
        "outputId": "a7c4a097-2454-49af-aeb7-9f2032a067ec"
      },
      "source": [
        "display_attention(src, translation, attention)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0KCsM3b1Pob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}